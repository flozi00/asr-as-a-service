# -*- coding: utf-8 -*-
# copied from https://github.com/zldzmfoq12/aud-crawler
import json
import os
import shutil
from collections import OrderedDict
from glob import glob

import pandas as pd
import tqdm
import yt_dlp as youtube_dl
from pydub import AudioSegment
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api._errors import NoTranscriptFound


class VCtube:
    def __init__(self, output_dir: str, youtube_url: str, lang: str) -> None:
        self.output_dir = output_dir
        self.youtube_url = youtube_url
        self.lang = lang

        # Delete directory if existing
        if os.path.exists(self.output_dir):
            shutil.rmtree(self.output_dir, ignore_errors=True)
        os.makedirs(self.output_dir, exist_ok=True)

    def download_audio(self) -> None:
        download_path = os.path.join(self.output_dir, "wavs/" + "%(id)s.%(ext)s")

        # youtube_dl options
        ydl_opts = {
            "format": "worstaudio",
            "postprocessors": [
                {
                    "key": "FFmpegExtractAudio",
                    "preferredcodec": "wav",
                    "preferredquality": "192",
                }
            ],
            "postprocessors_args": ["-ar", "16000"],
            "prefer_ffmpeg": True,
            "keepvideo": False,
            "outtmpl": download_path,
            "ignoreerrors": True,
        }

        try:
            with youtube_dl.YoutubeDL(ydl_opts) as ydl:
                ydl.download([self.youtube_url])
        except Exception as e:
            print("error", e)

    def download_captions(self, skip_autogenerated=False) -> None:
        """Downloads the captions for the videos in the Youtube dataset.

        Args:
            skip_autogenerated (bool, optional): If True, skip autogenerated captions. Defaults to False.

        Returns:
            None
        """
        lang = self.lang
        video_id = []
        text = []
        start = []
        duration = []
        names = []
        full_names = []
        wav_dir = os.path.join(self.output_dir, "wavs")
        file_list = os.listdir(wav_dir)
        file_list_wav = [file for file in file_list if file.endswith(".wav")]
        for f in tqdm.tqdm(file_list_wav):
            try:
                video = f.split(".wav")[0]

                if skip_autogenerated:
                    try:
                        transcript_list = YouTubeTranscriptApi.list_transcripts(video)
                        subtitle = transcript_list.find_manually_created_transcript(
                            [lang]
                        )
                        subtitle = subtitle.fetch()
                    except NoTranscriptFound:
                        msg = "Skipping video {} because it has no manually generated subtitles"
                        print(msg.format(video))
                        continue
                else:
                    subtitle = YouTubeTranscriptApi.get_transcript(
                        video, languages=[lang]
                    )

                step_size = 12
                for subt in range(0, len(subtitle) - (step_size + 1), 2):
                    video_id.append(video)
                    full_name = os.path.join(
                        wav_dir, video + "." + str(subt).zfill(4) + ".wav"
                    )
                    full_names.append(full_name)
                    name = video + "." + str(subt).zfill(4) + ".wav"
                    names.append(name)
                    subtitle[subt]["text"] = "".join(
                        [
                            c
                            for c in " ".join(
                                subtitle[subt + x]["text"] for x in range(step_size)
                            )
                            if c not in ("!", "?", ",", ".", "\n", "~", '"', "'")
                        ]
                    )
                    text.append(subtitle[subt]["text"])
                    start.append(subtitle[subt]["start"])

                    duration.append(
                        subtitle[subt + step_size]["start"] - subtitle[subt]["start"]
                    )

            except Exception as e:
                print("error:", e)

        df = pd.DataFrame(
            {
                "id": video_id,
                "text": text,
                "start": start,
                "duration": duration,
                "name": full_names,
            }
        )
        text_dir = os.path.join(self.output_dir, "text")
        makedirs(text_dir)

        df.to_csv(text_dir + "/subtitle.csv", encoding="utf-8")
        res = [i + "|" + j for i, j in zip(names, text)]
        df2 = pd.DataFrame({"name": res})
        df2.to_csv(
            os.path.join(self.output_dir, "metadata.csv"),
            encoding="utf-8",
            header=False,
            index=False,
        )
        file_data = OrderedDict()
        for i in range(df.shape[0]):
            file_data[df["name"][i]] = df["text"][i]
        with open(
            os.path.join(self.output_dir, "alignment.json"), "w", encoding="utf-8"
        ) as make_file:
            json.dump(file_data, make_file, ensure_ascii=False, indent="\n")

        print(os.path.basename(self.output_dir) + " channel was finished")

    def audio_split(self, parallel=False) -> None:
        base_dir = self.output_dir + "/wavs/*.wav"
        audio_paths = glob(base_dir)
        audio_paths.sort()
        parallel_run(audio_paths, desc="Split with caption", parallel=parallel)


def split_with_caption(audio_path, skip_idx=0, out_ext="wav") -> list:
    df = pd.read_csv(audio_path.split("wavs")[0] + "text/subtitle.csv")
    filename = os.path.basename(audio_path).split(".", 1)[0]

    audio = read_audio(audio_path)
    df2 = df[df["id"].apply(str) == filename]
    df2["end"] = round((df2["start"] + df2["duration"]) * 1000).astype(int)
    df2["start"] = round(df2["start"] * 1000).astype(int)
    edges = df2[["start", "end"]].values.tolist()

    audio_paths = []
    for idx, (start_idx, end_idx) in enumerate(edges[skip_idx:]):
        start_idx = max(0, start_idx)

        target_audio_path = "{}/{}.{:04d}.{}".format(
            os.path.dirname(audio_path), filename, idx, out_ext
        )

        segment = audio[start_idx:end_idx]

        segment.export(target_audio_path, format=out_ext)  # for soundsegment

        audio_paths.append(target_audio_path)

    return audio_paths


def read_audio(audio_path):
    return AudioSegment.from_file(audio_path).set_channels(1).set_frame_rate(16000)


# -*- coding: utf-8 -*-
import os
import re
import sys
import json
import requests
import subprocess
from tqdm import tqdm
from contextlib import closing
from multiprocessing import Pool
from collections import namedtuple
from datetime import datetime, timedelta
from shutil import copyfile as copy_file

PARAMS_NAME = "params.json"


class ValueWindow:
    def __init__(self, window_size=100):
        self._window_size = window_size
        self._values = []

    def append(self, x):
        self._values = self._values[-(self._window_size - 1) :] + [x]

    @property
    def sum(self):
        return sum(self._values)

    @property
    def count(self):
        return len(self._values)

    @property
    def average(self):
        return self.sum / max(1, self.count)

    def reset(self):
        self._values = []


def prepare_dirs(config, hparams):
    if hasattr(config, "data_paths"):
        config.datasets = [
            os.path.basename(data_path) for data_path in config.data_paths
        ]
        dataset_desc = "+".join(config.datasets)

    if config.load_path:
        config.model_dir = config.load_path
    else:
        config.model_name = "{}_{}".format(dataset_desc, get_time())
        config.model_dir = os.path.join(config.log_dir, config.model_name)

        for path in [config.log_dir, config.model_dir]:
            if not os.path.exists(path):
                os.makedirs(path)

    if config.load_path:
        load_hparams(hparams, config.model_dir)
    else:
        setattr(hparams, "num_speakers", len(config.datasets))

        save_hparams(config.model_dir, hparams)
        copy_file("hparams.py", os.path.join(config.model_dir, "hparams.py"))


def makedirs(path):
    if not os.path.exists(path):
        print(" [*] Make directories : {}".format(path))
        os.makedirs(path)


def remove_file(path):
    if os.path.exists(path):
        print(" [*] Removed: {}".format(path))
        os.remove(path)


def backup_file(path):
    root, ext = os.path.splitext(path)
    new_path = "{}.backup_{}{}".format(root, get_time(), ext)

    os.rename(path, new_path)
    print(" [*] {} has backup: {}".format(path, new_path))


def get_time():
    return datetime.now().strftime("%Y-%m-%d_%H-%M-%S")


def write_json(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4, sort_keys=True, ensure_ascii=False)


def load_json(path, as_class=False, encoding="utf-8"):
    with open(path, encoding=encoding) as f:
        content = f.read()
        content = re.sub(",\s*}", "}", content)
        content = re.sub(",\s*]", "]", content)

        if as_class:
            data = json.loads(
                content,
                object_hook=lambda data: namedtuple("Data", data.keys())(
                    *data.values()
                ),
            )
        else:
            data = json.loads(content)
    # print(data)
    return data


def save_hparams(model_dir, hparams):
    param_path = os.path.join(model_dir, PARAMS_NAME)

    info = eval(hparams.to_json().replace("true", "True").replace("false", "False"))
    write_json(param_path, info)

    print(" [*] MODEL dir: {}".format(model_dir))
    print(" [*] PARAM path: {}".format(param_path))


def load_hparams(hparams, load_path, skip_list=[]):
    path = os.path.join(load_path, PARAMS_NAME)

    new_hparams = load_json(path)
    hparams_keys = vars(hparams).keys()

    for key, value in new_hparams.items():
        if key in skip_list or key not in hparams_keys:
            print("Skip {} because it not exists".format(key))
            continue

        if (
            key not in ["job_name", "num_workers", "display", "is_train", "load_path"]
            or key == "pointer_load_path"
        ):
            original_value = getattr(hparams, key)
            if original_value != value:
                print("UPDATE {}: {} -> {}".format(key, getattr(hparams, key), value))
                setattr(hparams, key, value)


def add_prefix(path, prefix):
    dir_path, filename = os.path.dirname(path), os.path.basename(path)
    return "{}/{}.{}".format(dir_path, prefix, filename)


def add_postfix(path, postfix):
    path_without_ext, ext = path.rsplit(".", 1)
    return "{}.{}.{}".format(path_without_ext, postfix, ext)


def remove_postfix(path):
    items = path.rsplit(".", 2)
    return items[0] + "." + items[2]


def parallel_run(items, desc="", parallel=True):
    results = []
    for item in tqdm.tqdm(items, total=len(items), desc=desc):
        out = split_with_caption(item)
        if out is not None:
            results.append(out)

    return results


def which(program):
    if os.name == "nt" and not program.endswith(".exe"):
        program += ".exe"

    envdir_list = [os.curdir] + os.environ["PATH"].split(os.pathsep)

    for envdir in envdir_list:
        program_path = os.path.join(envdir, program)
        if os.path.isfile(program_path) and os.access(program_path, os.X_OK):
            return program_path


def get_encoder_name():
    if which("avconv"):
        return "avconv"
    elif which("ffmpeg"):
        return "ffmpeg"
    else:
        return "ffmpeg"


def download_with_url(url, dest_path, chunk_size=32 * 1024):
    with open(dest_path, "wb") as f:
        response = requests.get(url, stream=True)
        total_size = int(response.headers.get("content-length", 0))

        for chunk in response.iter_content(chunk_size):
            if chunk:  # filter out keep-alive new chunks
                f.write(chunk)
    return True


def str2bool(v):
    return v.lower() in ("true", "1")


def get_git_revision_hash():
    return subprocess.check_output(["git", "rev-parse", "HEAD"]).decode("utf-8")


def get_git_diff():
    return subprocess.check_output(["git", "diff"]).decode("utf-8")


def warning(msg):
    print("=" * 40)
    print(" [!] {}".format(msg))
    print("=" * 40)
    print()


def query_yes_no(question, default=None):
    # Code from https://stackoverflow.com/a/3041990
    valid = {"yes": True, "y": True, "ye": True, "no": False, "n": False}
    if default is None:
        prompt = " [y/n] "
    elif default == "yes":
        prompt = " [Y/n] "
    elif default == "no":
        prompt = " [y/N] "
    else:
        raise ValueError("invalid default answer: '%s'" % default)

    while True:
        sys.stdout.write(question + prompt)
        choice = input().lower()
        if default is not None and choice == "":
            return valid[default]
        elif choice in valid:
            return valid[choice]
        else:
            sys.stdout.write("Please respond with 'yes' or 'no' " "(or 'y' or 'n').\n")


import os
import re
import sys
import json
import tqdm
import pandas as pd
from functools import partial
from collections import OrderedDict
from youtube_transcript_api import YouTubeTranscriptApi


def download_captions(channels):
    base_dir = "./datasets/"
    c = channels
    print(c)
    video_id = []
    text = []
    start = []
    duration = []
    names = []
    file_list = os.listdir(base_dir + c + "/audio/")
    file_list_wav = [file for file in file_list if file.endswith(".wav")]
    # print(file_list_wav)
    for f in tqdm.tqdm(file_list_wav):
        try:
            video = f.split(".wav")[0]
            subtitle = YouTubeTranscriptApi.get_transcript(video)
            # print(subtitle)
            # break
            for s in range(len(subtitle) - 1):
                # print(s)
                video_id.append(video)
                name = base_dir + c + "/audio/" + video + "." + str(s).zfill(4) + ".wav"
                names.append(name)
                # print(subtitle[s]['text'])
                subtitle[s]["text"] = "".join(
                    [
                        c
                        for c in subtitle[s]["text"]
                        if c not in ("!", "?", ",", ".", "\n", "~", '"', "'")
                    ]
                )
                # print(subtitle[s])
                text.append(subtitle[s]["text"])
                start.append(subtitle[s]["start"])
                duration.append(subtitle[s + 1]["start"] - subtitle[s]["start"])
        except:
            # print(e)
            pass

    print(len(text), len(start), len(duration), len(names))
    df = pd.DataFrame(
        {
            "id": video_id,
            "text": text,
            "start": start,
            "duration": duration,
            "name": names,
        }
    )
    makedirs(base_dir + c + "/text")
    df.to_csv(base_dir + c + "/text/subtitle.csv", encoding="utf-8")
    file_data = OrderedDict()
    for i in range(df.shape[0]):
        file_data[df["name"][i]] = df["text"][i]
    with open(base_dir + c + "/alignment.json", "w", encoding="utf-8") as make_file:
        json.dump(file_data, make_file, ensure_ascii=False, indent="\n")
    print(c + " channel was finished")


def download_caption_batch(channels):
    print(channels)
    download_captions(channels)
    # fn = partial(download_captions)
    #
    # parallel_run(fn, channels,
    #         desc="Download caption", parallel=False)

